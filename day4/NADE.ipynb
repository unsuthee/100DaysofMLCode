{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "==>>> total trainning batch number: 600\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = datasets.MNIST('../datasets/mnist', train=True, download=True, transform=trans)\n",
    "test_set = datasets.MNIST('../datasets/mnist', train=False, download=True, transform=trans)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "\n",
    "print('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NADE(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_feas, num_hidden_dim):\n",
    "        super(NADE, self).__init__()\n",
    "        \n",
    "        self.num_feas = num_feas\n",
    "        self.num_hidden_dim = num_hidden_dim\n",
    "\n",
    "        self.C = Parameter(torch.randn(1, num_hidden_dim))\n",
    "        self.W = Parameter(torch.randn(num_feas, num_hidden_dim))\n",
    "        self.B = Parameter(torch.randn(num_feas))\n",
    "        \n",
    "    def forward(self, batch_x):\n",
    "        prob_mat = torch.empty(self.num_feas).type(torch.cuda.FloatTensor)\n",
    "        prob_mat[0] = F.sigmoid(torch.mv(self.C, self.W[0]) + self.B[0])\n",
    "        loss = 0.\n",
    "        for x in batch_x:\n",
    "            for i in range(1, self.num_feas):\n",
    "                t = x[:i].unsqueeze(0)\n",
    "                h = F.sigmoid(torch.mm(t, self.W[:i]) + self.C)\n",
    "                prob_mat[i] = F.sigmoid(torch.mv(h, self.W[i]) + self.B[i])\n",
    "            loss += F.binary_cross_entropy(prob_mat, (x > 0).type(torch.cuda.FloatTensor))\n",
    "        return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NADE(784, 32)\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "i = 0\n",
    "for batch_x, batch_y in tqdm(train_loader):\n",
    "    batch_x = batch_x.view(-1, 784)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = model(batch_x.cuda())\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    i+=1\n",
    "    if i % 100 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch_x[15].view(28,28) > 0.0, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research2018",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
