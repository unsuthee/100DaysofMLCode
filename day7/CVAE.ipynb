{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 600\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = datasets.MNIST('../datasets/mnist', train=True, download=True, transform=trans)\n",
    "test_set = datasets.MNIST('../datasets/mnist', train=False, download=True, transform=trans)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "\n",
    "print('==>>> total trainning batch number: {}'.format(len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    " \n",
    "    def forward(self, input):\n",
    "        return input.view(*self.shape)\n",
    "    \n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(CVAE, self).__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "            \n",
    "        # encoder\n",
    "        self.enc = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    torch.nn.ZeroPad2d((0, 1, 0, 1)),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    Reshape(-1, 64*4*4))\n",
    "        \n",
    "        self.h_to_mu = nn.Linear(64*4*4, latent_size)\n",
    "        self.h_to_logvar = nn.Sequential(nn.Linear(64*4*4, latent_size),\n",
    "                                         nn.Sigmoid())\n",
    "\n",
    "        # discriminator\n",
    "#         self.d = nn.Sequential(nn.Conv2d(1, latent_dim, kernel_size=3, stride=2, padding=1),\n",
    "#                     nn.BatchNorm2d(64),\n",
    "#                     nn.LeakyReLU(inplace=True),\n",
    "#                     nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "#                     nn.BatchNorm2d(128),\n",
    "#                     nn.LeakyReLU(inplace=True),\n",
    "#                     Reshape(-1, 128*7*7),\n",
    "#                     nn.Linear(128*7*7, 128),\n",
    "#                     nn.LeakyReLU(inplace=True),\n",
    "#                     nn.Linear(128, 10),\n",
    "#                     nn.Softmax(dim=1))\n",
    "        \n",
    "        # decoder\n",
    "        self.dec = nn.Sequential(nn.Linear(latent_size + 10, 64*4*4),\n",
    "                                 nn.LeakyReLU(),\n",
    "                                 nn.Linear(64*4*4, 64*4*4),\n",
    "                    Reshape(-1, 64, 4, 4),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    torch.nn.ZeroPad2d((0, -1, 0, -1)),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    nn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 1, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.Tanh())\n",
    "        \n",
    "    def encode(self, xb):\n",
    "        h = self.enc(xb)\n",
    "        z_mu = self.h_to_mu(h)\n",
    "        z_logvar = self.h_to_logvar(h)\n",
    "        return z_mu, z_logvar\n",
    "    \n",
    "    def decode(self, zb):\n",
    "        xb_hat = self.dec(zb)\n",
    "        return xb_hat\n",
    "        \n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = torch.sqrt(torch.exp(logvar))\n",
    "        eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def forward(self, xb, yb):\n",
    "        zb_mu, zb_logvar = self.encode(xb)\n",
    "        zb = self.reparametrize(zb_mu, zb_logvar)\n",
    "        \n",
    "        zyb = torch.cat([zb, yb], dim=1)\n",
    "        \n",
    "        xb_hat = self.decode(zyb)\n",
    "        return xb_hat, zb_mu, zb_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVAE(\n",
       "  (enc): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (6): ZeroPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (10): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (13): Reshape()\n",
       "  )\n",
       "  (h_to_mu): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (h_to_logvar): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (dec): Sequential(\n",
       "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (3): Reshape()\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (6): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (8): ZeroPad2d(padding=(0, -1, 0, -1), value=0)\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (11): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (13): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (15): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (16): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (17): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_size = 64\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "model = CVAE(latent_size)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:12<00:00, 46.42it/s]\n",
      "  1%|          | 6/600 [00:00<00:10, 55.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1282.8469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:11<00:00, 54.14it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 53.02it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 53.07it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.46it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 53.15it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 52.86it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.43it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.08it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 53.60it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 53.63it/s]\n",
      "  1%|          | 6/600 [00:00<00:10, 54.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 820.7140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:11<00:00, 54.42it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 55.47it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 54.90it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 54.76it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 54.58it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 54.65it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 56.05it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 56.40it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.31it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 55.68it/s]\n",
      "  1%|          | 6/600 [00:00<00:10, 54.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 785.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:10<00:00, 54.72it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 54.63it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 53.96it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.22it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.54it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 55.99it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.49it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.30it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.27it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.44it/s]\n",
      "  1%|          | 6/600 [00:00<00:11, 53.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 696.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:11<00:00, 54.52it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.17it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.48it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 54.69it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 52.78it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.41it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 52.21it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.22it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 53.67it/s]\n",
      "100%|██████████| 600/600 [00:11<00:00, 54.09it/s]\n",
      "  1%|          | 6/600 [00:00<00:11, 52.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 673.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:10<00:00, 54.62it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 56.07it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 56.10it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 56.01it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 55.42it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 54.85it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 56.35it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 56.24it/s]\n",
      "100%|██████████| 600/600 [00:10<00:00, 55.42it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_digit_vector(zb, digit, num_classes=10):\n",
    "    target_digit = digit * torch.ones(z_samples.size(0)).type(torch.LongTensor)\n",
    "    target_digit = torch.eye(num_classes)[target_digit]\n",
    "    target_digit = Variable(target_digit).cuda()\n",
    "    return torch.cat([zb, target_digit], dim=1)\n",
    "\n",
    "mse_loss = nn.MSELoss(size_average=False)\n",
    "\n",
    "def kl_loss(mu, logvar):\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element, dim=1)\n",
    "    KLD = torch.mean(KLD).mul_(-0.5)\n",
    "    return KLD\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "kl_weight = 0.\n",
    "kl_steps = 1. / 2000.\n",
    "\n",
    "with open('loss.cvae.log', 'w') as log_fn:\n",
    "    \n",
    "    log_fn.write('epoch,reconstr_error,kldiv_error,num_batches\\n')\n",
    "\n",
    "    num_epochs = 50\n",
    "    num_classes = 10\n",
    "    \n",
    "    z_samples = torch.randn(16, latent_size)\n",
    "    z_samples = Variable(z_samples).cuda()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for xb, yb in tqdm(train_loader):\n",
    "            xb = Variable(xb).cuda()\n",
    "            batch_size = xb.size(0)\n",
    "            \n",
    "            yb = torch.eye(num_classes)[yb]\n",
    "            yb = Variable(yb).cuda()\n",
    "            \n",
    "            kl_weight += kl_steps\n",
    "            kl_weight = min(1.0, kl_weight)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            xb_hat, zb_mu, zb_logvar = model(xb, yb)\n",
    "            reconstr_loss = mse_loss(xb_hat, xb)\n",
    "            kldiv_loss = kl_weight * kl_loss(zb_mu, zb_logvar)\n",
    "            loss = reconstr_loss + kldiv_loss\n",
    "\n",
    "            log_fn.write(\"{},{},{},{}\\n\".format(epoch, reconstr_loss.item(), kldiv_loss.item(), batch_size))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            for digit in range(0, 10):\n",
    "                test_images = model.decode(generate_digit_vector(z_samples, digit))\n",
    "                np.save('img/generated_img.cvae.{}.epoch{}'.format(digit, epoch), test_images.data.cpu().numpy())\n",
    "            tqdm.write(\"loss: {:.4f}\".format(loss.item()))\n",
    "\n",
    "epoch = 50\n",
    "for digit in range(0, 10):\n",
    "    test_images = model.decode(generate_digit_vector(z_samples, digit))\n",
    "    np.save('img/generated_img.cvae.{}.epoch{}'.format(digit, epoch), test_images.data.cpu().numpy())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research2018",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
