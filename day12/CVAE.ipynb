{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "dataset = 'MNIST'\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "if dataset == 'FashionMNIST':\n",
    "    train_set = datasets.FashionMNIST('../datasets/fashion_mnist', train=True, download=True, transform=trans)\n",
    "elif dataset == 'MNIST':\n",
    "    train_set = datasets.MNIST('../datasets/mnist', train=True, download=True, transform=trans)\n",
    "    \n",
    "\n",
    "mnist_data = []\n",
    "for idx in range(len(train_set)):\n",
    "    data = {'idx': idx, 'img': train_set[idx][0], 'label': train_set[idx][1].item()}\n",
    "    mnist_data.append(data)\n",
    "mnist_df = pd.DataFrame.from_dict(mnist_data)\n",
    "\n",
    "label_percent = 0.1\n",
    "\n",
    "frames = []\n",
    "for digit in range(10):\n",
    "    frames.append(mnist_df[mnist_df.label == digit].sample(frac=label_percent))\n",
    "train_labeled_df = pd.concat(frames)\n",
    "mnist_df = mnist_df.drop(list(train_labeled_df.idx))\n",
    "\n",
    "train_labeled_df.to_pickle('{}.train_labeled_df.pkl'.format(dataset))\n",
    "mnist_df.to_pickle('{}.train_unlabeled_df.pkl'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "######################################################################################################################\n",
    "class SemiSupervisedDataset(Dataset):\n",
    "    def __init__(self, dataset, label=True):\n",
    "        self.label = label\n",
    "        if label:\n",
    "            self.df = pd.read_pickle('{}.train_labeled_df.pkl'.format(dataset))\n",
    "        else:\n",
    "            self.df = pd.read_pickle('{}.train_unlabeled_df.pkl'.format(dataset))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.df.iloc[idx].img\n",
    "        label = int(self.df.iloc[idx].label)\n",
    "        return (img, label)\n",
    "    \n",
    "######################################################################################################################\n",
    "batch_size = 64\n",
    "z_dim = 62\n",
    "y_dim = 10\n",
    "\n",
    "dataset = 'MNIST'\n",
    "\n",
    "labeled_train_set = SemiSupervisedDataset(dataset, label=True)\n",
    "unlabeled_train_set = SemiSupervisedDataset(dataset, label=False)\n",
    "\n",
    "labeled_train_loader = torch.utils.data.DataLoader(dataset=labeled_train_set, batch_size=batch_size, shuffle=True)\n",
    "unlabeled_train_loader = torch.utils.data.DataLoader(dataset=unlabeled_train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, dataset, latent_dim, num_classes, device):\n",
    "        super(CVAE, self).__init__()\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        \n",
    "        if dataset == 'MNIST':\n",
    "            self.input_dim = 1 # the number of input channel \n",
    "            self.input_height = 28\n",
    "            self.input_width = 28\n",
    "        else:\n",
    "            assert(False)\n",
    "            \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * (self.input_height // 4) * (self.input_width // 4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.h_to_mu = nn.Sequential(nn.Linear(1024, self.latent_dim))\n",
    "        self.h_to_logvar = nn.Sequential(nn.Linear(1024, self.latent_dim),\n",
    "                                         nn.Sigmoid())\n",
    "        \n",
    "        if dataset == 'MNIST':\n",
    "            self.generator_input_dim = latent_dim + num_classes\n",
    "            self.output_dim = 1\n",
    "        else:\n",
    "            assert(False)\n",
    "            \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.generator_input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128 * (self.input_height // 4) * (self.input_width // 4)),\n",
    "            nn.BatchNorm1d(128 * (self.input_height // 4) * (self.input_width // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = torch.sqrt(torch.exp(logvar))\n",
    "        eps = torch.randn_like(logvar)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def encode(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 128 * (self.input_height // 4) * (self.input_width // 4))\n",
    "        h = self.fc1(x)\n",
    "        \n",
    "        z_mu = self.h_to_mu(h)\n",
    "        z_logvar = self.h_to_logvar(h)\n",
    "        return z_mu, z_logvar\n",
    "    \n",
    "    def decode(self, input, label):\n",
    "        zy = torch.cat([input, label], 1)\n",
    "        h = self.fc2(zy)\n",
    "        h = h.view(-1, 128, (self.input_height // 4), (self.input_width // 4))\n",
    "        x_hat = self.deconv(h)\n",
    "        return x_hat\n",
    "    \n",
    "    def forward(self, input, label):\n",
    "        z_mu, z_logvar = self.encode(input)\n",
    "        z = self.reparametrize(z_mu, z_logvar)\n",
    "        x_hat = self.decode(z, label)\n",
    "        return x_hat, z_mu, z_logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss(size_average=False)\n",
    "\n",
    "def compute_kl_loss(mu, logvar):\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element, dim=1)\n",
    "    KLD = torch.mean(KLD).mul_(-0.5)\n",
    "    return KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CVAE(dataset, z_dim, y_dim, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss:1074.7564\n",
      "epoch:1 loss:512.9606\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "kl_weight = 0.\n",
    "kl_step = 1 / 5000.\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = []\n",
    "    for xb, yb in unlabeled_train_loader:\n",
    "        y_onehot = torch.zeros((xb.size(0), y_dim))\n",
    "        y_onehot = y_onehot.scatter_(1, yb.unsqueeze(1), 1)\n",
    "\n",
    "        xb = xb.to(device)\n",
    "        y_onehot = y_onehot.to(device)\n",
    "        \n",
    "        xb_hat, z_mu, z_logvar = model(xb, y_onehot)\n",
    "        kl_loss = compute_kl_loss(z_mu, z_logvar)\n",
    "        reconstr_loss = mse_loss(xb_hat, xb)\n",
    "        loss = reconstr_loss + kl_weight * kl_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        kl_weight = min(kl_weight + kl_step, 1.0)\n",
    "        avg_loss.append(loss.item())\n",
    "    \n",
    "    print('epoch:{} loss:{:.4f}'.format(epoch, np.mean(avg_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed noise & condition\n",
    "sample_num = 100\n",
    "sample_z_ = torch.zeros((sample_num, z_dim))\n",
    "for i in range(10):\n",
    "    sample_z_[i*y_dim] = torch.randn(1, z_dim)\n",
    "    for j in range(1, y_dim):\n",
    "        sample_z_[i*y_dim + j] = sample_z_[i*y_dim]\n",
    "        \n",
    "temp = torch.zeros((10, 1))\n",
    "for i in range(y_dim):\n",
    "    temp[i, 0] = i\n",
    "    \n",
    "temp_y = torch.zeros((sample_num, 1))\n",
    "for i in range(10):\n",
    "    temp_y[i*y_dim: (i+1)*y_dim] = temp\n",
    "    \n",
    "sample_y_ = torch.zeros((sample_num, y_dim))\n",
    "sample_y_.scatter_(1, temp_y.type(torch.LongTensor), 1); # convert to one-hot\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_z_ = sample_z_.to(device)\n",
    "    sample_y_ = sample_y_.to(device)\n",
    "    samples = model.decode(sample_z_, sample_y_)\n",
    "    samples = samples.permute(0, 2, 3, 1).data.cpu().numpy()\n",
    "    np.save('samples.cvae', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "sample_images = np.load('samples.cvae.npy')\n",
    "sample_images = sample_images.reshape(10, 10, 28, 28, 1).squeeze()\n",
    "\n",
    "full_images = []\n",
    "for i in range(10):\n",
    "    tmp = [sample_images[i, j, :, :] for j in range(10)]\n",
    "    full_images.append(np.hstack(tmp))\n",
    "full_images = np.vstack(full_images)   \n",
    "\n",
    "plt.imshow(full_images, cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research2018",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
